{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3649,"databundleVersionId":46718,"sourceType":"competition"}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-04T15:32:01.813344Z","iopub.execute_input":"2023-12-04T15:32:01.813734Z","iopub.status.idle":"2023-12-04T15:32:02.163966Z","shell.execute_reply.started":"2023-12-04T15:32:01.813691Z","shell.execute_reply":"2023-12-04T15:32:02.162951Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar-10/trainLabels.csv\n/kaggle/input/cifar-10/sampleSubmission.csv\n/kaggle/input/cifar-10/test.7z\n/kaggle/input/cifar-10/train.7z\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout,Flatten,BatchNormalization,Conv2D,MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\n# Load the CIFAR-10 dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Data augmentation is used for generation of more images from existing images as we know that deep learning \n# is data hunry process\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\n# Preprocess and augment the training data(standarization)\nx_train = x_train / 255.0\nx_test = x_test / 255.0\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:32:23.863722Z","iopub.execute_input":"2023-12-04T15:32:23.864447Z","iopub.status.idle":"2023-12-04T15:32:41.402330Z","shell.execute_reply.started":"2023-12-04T15:32:23.864413Z","shell.execute_reply":"2023-12-04T15:32:41.401282Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 5s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating my own CNN model .","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (32, 32, 3)\nKERNEL_SIZE = (3, 3)\nmodel = Sequential()\n\n# Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n#model.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n#model.add(BatchNormalization())\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Dropout layers\n#model.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=256, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:32:43.408401Z","iopub.execute_input":"2023-12-04T15:32:43.409380Z","iopub.status.idle":"2023-12-04T15:32:48.585771Z","shell.execute_reply.started":"2023-12-04T15:32:43.409338Z","shell.execute_reply":"2023-12-04T15:32:48.585015Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    if epoch < 15:\n        return 0.001\n    if epoch < 30:\n        return 0.0001\n    return 0.00001\n\n# Compile the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model with data augmentation and learning rate scheduling\nbatch_size = 100\nepochs = 30\nmodel.fit(\n    datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(x_train) / batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[LearningRateScheduler(lr_schedule)])\n\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:32:54.315053Z","iopub.execute_input":"2023-12-04T15:32:54.315755Z","iopub.status.idle":"2023-12-04T15:47:57.976880Z","shell.execute_reply.started":"2023-12-04T15:32:54.315726Z","shell.execute_reply":"2023-12-04T15:47:57.975857Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-12-04 15:32:56.932544: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"500/500 [==============================] - 47s 62ms/step - loss: 2.0960 - accuracy: 0.2183 - val_loss: 2.3165 - val_accuracy: 0.2409 - lr: 0.0010\nEpoch 2/30\n500/500 [==============================] - 30s 60ms/step - loss: 1.7729 - accuracy: 0.3362 - val_loss: 1.9015 - val_accuracy: 0.3482 - lr: 0.0010\nEpoch 3/30\n500/500 [==============================] - 30s 59ms/step - loss: 1.5735 - accuracy: 0.4252 - val_loss: 1.3276 - val_accuracy: 0.5308 - lr: 0.0010\nEpoch 4/30\n500/500 [==============================] - 29s 59ms/step - loss: 1.3969 - accuracy: 0.5026 - val_loss: 1.4892 - val_accuracy: 0.5183 - lr: 0.0010\nEpoch 5/30\n500/500 [==============================] - 29s 59ms/step - loss: 1.2657 - accuracy: 0.5595 - val_loss: 1.0321 - val_accuracy: 0.6368 - lr: 0.0010\nEpoch 6/30\n500/500 [==============================] - 30s 59ms/step - loss: 1.1765 - accuracy: 0.5965 - val_loss: 1.1202 - val_accuracy: 0.6376 - lr: 0.0010\nEpoch 7/30\n500/500 [==============================] - 30s 59ms/step - loss: 1.0940 - accuracy: 0.6257 - val_loss: 1.3375 - val_accuracy: 0.6109 - lr: 0.0010\nEpoch 8/30\n500/500 [==============================] - 29s 59ms/step - loss: 1.0348 - accuracy: 0.6509 - val_loss: 1.1591 - val_accuracy: 0.6345 - lr: 0.0010\nEpoch 9/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.9857 - accuracy: 0.6681 - val_loss: 0.8374 - val_accuracy: 0.7134 - lr: 0.0010\nEpoch 10/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.9500 - accuracy: 0.6845 - val_loss: 0.8977 - val_accuracy: 0.6961 - lr: 0.0010\nEpoch 11/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.9188 - accuracy: 0.6934 - val_loss: 1.0853 - val_accuracy: 0.6456 - lr: 0.0010\nEpoch 12/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.8838 - accuracy: 0.7043 - val_loss: 0.9067 - val_accuracy: 0.6983 - lr: 0.0010\nEpoch 13/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.8544 - accuracy: 0.7170 - val_loss: 0.7247 - val_accuracy: 0.7502 - lr: 0.0010\nEpoch 14/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.8276 - accuracy: 0.7234 - val_loss: 0.7417 - val_accuracy: 0.7513 - lr: 0.0010\nEpoch 15/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.8062 - accuracy: 0.7315 - val_loss: 0.8484 - val_accuracy: 0.7291 - lr: 0.0010\nEpoch 16/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.7334 - accuracy: 0.7551 - val_loss: 0.5790 - val_accuracy: 0.8019 - lr: 1.0000e-04\nEpoch 17/30\n500/500 [==============================] - 30s 60ms/step - loss: 0.7123 - accuracy: 0.7626 - val_loss: 0.5893 - val_accuracy: 0.7985 - lr: 1.0000e-04\nEpoch 18/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.7006 - accuracy: 0.7683 - val_loss: 0.5710 - val_accuracy: 0.8049 - lr: 1.0000e-04\nEpoch 19/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.6930 - accuracy: 0.7690 - val_loss: 0.6067 - val_accuracy: 0.7968 - lr: 1.0000e-04\nEpoch 20/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.6845 - accuracy: 0.7707 - val_loss: 0.5426 - val_accuracy: 0.8158 - lr: 1.0000e-04\nEpoch 21/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.6737 - accuracy: 0.7732 - val_loss: 0.5571 - val_accuracy: 0.8113 - lr: 1.0000e-04\nEpoch 22/30\n500/500 [==============================] - 29s 58ms/step - loss: 0.6709 - accuracy: 0.7767 - val_loss: 0.5781 - val_accuracy: 0.8065 - lr: 1.0000e-04\nEpoch 23/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.6643 - accuracy: 0.7785 - val_loss: 0.5354 - val_accuracy: 0.8181 - lr: 1.0000e-04\nEpoch 24/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.6601 - accuracy: 0.7794 - val_loss: 0.5385 - val_accuracy: 0.8189 - lr: 1.0000e-04\nEpoch 25/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.6467 - accuracy: 0.7829 - val_loss: 0.5199 - val_accuracy: 0.8246 - lr: 1.0000e-04\nEpoch 26/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.6472 - accuracy: 0.7851 - val_loss: 0.5601 - val_accuracy: 0.8119 - lr: 1.0000e-04\nEpoch 27/30\n500/500 [==============================] - 29s 59ms/step - loss: 0.6423 - accuracy: 0.7841 - val_loss: 0.5206 - val_accuracy: 0.8270 - lr: 1.0000e-04\nEpoch 28/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.6348 - accuracy: 0.7866 - val_loss: 0.5249 - val_accuracy: 0.8219 - lr: 1.0000e-04\nEpoch 29/30\n500/500 [==============================] - 30s 59ms/step - loss: 0.6390 - accuracy: 0.7847 - val_loss: 0.5393 - val_accuracy: 0.8189 - lr: 1.0000e-04\nEpoch 30/30\n500/500 [==============================] - 30s 60ms/step - loss: 0.6377 - accuracy: 0.7871 - val_loss: 0.5248 - val_accuracy: 0.8230 - lr: 1.0000e-04\n313/313 [==============================] - 1s 4ms/step - loss: 0.5248 - accuracy: 0.8230\nTest Accuracy: 82.30%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Making my CNN model more complex by adding more layers.","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (32, 32, 3)\nKERNEL_SIZE = (3, 3)\nmodel = Sequential()\n\n# Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n#model.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n#model.add(BatchNormalization())\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Dropout layers\n#model.add(Dropout(0.5))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:48:46.404654Z","iopub.execute_input":"2023-12-04T15:48:46.405077Z","iopub.status.idle":"2023-12-04T15:48:46.472938Z","shell.execute_reply.started":"2023-12-04T15:48:46.405044Z","shell.execute_reply":"2023-12-04T15:48:46.472121Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    if epoch < 15:\n        return 0.001\n    if epoch < 30:\n        return 0.0001\n    return 0.00001\n\n# Compile the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model with data augmentation and learning rate scheduling\nbatch_size = 100\nepochs = 30\n# history=model.fit(\n#     datagen.flow(x_train, y_train, batch_size=batch_size),\n#     steps_per_epoch=len(x_train) / batch_size,\n#     epochs=epochs,\n#     validation_data=(x_test, y_test))\n\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:48:54.487279Z","iopub.execute_input":"2023-12-04T15:48:54.487640Z","iopub.status.idle":"2023-12-04T15:48:55.948546Z","shell.execute_reply.started":"2023-12-04T15:48:54.487610Z","shell.execute_reply":"2023-12-04T15:48:55.947580Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 3ms/step - loss: 2.3092 - accuracy: 0.0878\nTest Accuracy: 8.78%\n","output_type":"stream"}]},{"cell_type":"code","source":"model6 = Sequential()\nmodel6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.25))\nmodel6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.25))\nmodel6.add(Flatten())\nmodel6.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel6.add(BatchNormalization())\nmodel6.add(Dropout(0.5))\nmodel6.add(Dense(10, activation='softmax'))\n# compile model\n# opt = SGD(lr=0.001, momentum=0.9)\nmodel6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nbatch_size = 100\nepochs = 50\nhistory=model6.fit(\n    datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(x_train) / batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[LearningRateScheduler(lr_schedule)])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:49:02.907616Z","iopub.execute_input":"2023-12-04T15:49:02.908218Z","iopub.status.idle":"2023-12-04T16:13:37.817747Z","shell.execute_reply.started":"2023-12-04T15:49:02.908183Z","shell.execute_reply":"2023-12-04T16:13:37.816923Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-12-04 15:49:05.454072: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_5/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"500/500 [==============================] - 35s 60ms/step - loss: 1.7985 - accuracy: 0.3836 - val_loss: 1.4035 - val_accuracy: 0.4998 - lr: 0.0010\nEpoch 2/50\n500/500 [==============================] - 30s 59ms/step - loss: 1.3361 - accuracy: 0.5225 - val_loss: 1.3899 - val_accuracy: 0.5297 - lr: 0.0010\nEpoch 3/50\n500/500 [==============================] - 30s 59ms/step - loss: 1.1514 - accuracy: 0.5912 - val_loss: 1.1702 - val_accuracy: 0.6009 - lr: 0.0010\nEpoch 4/50\n500/500 [==============================] - 30s 59ms/step - loss: 1.0377 - accuracy: 0.6364 - val_loss: 1.0834 - val_accuracy: 0.6340 - lr: 0.0010\nEpoch 5/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.9518 - accuracy: 0.6664 - val_loss: 0.8855 - val_accuracy: 0.6968 - lr: 0.0010\nEpoch 6/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.8882 - accuracy: 0.6896 - val_loss: 0.7746 - val_accuracy: 0.7312 - lr: 0.0010\nEpoch 7/50\n500/500 [==============================] - 30s 60ms/step - loss: 0.8348 - accuracy: 0.7112 - val_loss: 0.8038 - val_accuracy: 0.7265 - lr: 0.0010\nEpoch 8/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.7944 - accuracy: 0.7264 - val_loss: 0.8113 - val_accuracy: 0.7268 - lr: 0.0010\nEpoch 9/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.7652 - accuracy: 0.7360 - val_loss: 0.8419 - val_accuracy: 0.7258 - lr: 0.0010\nEpoch 10/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.7295 - accuracy: 0.7484 - val_loss: 0.6834 - val_accuracy: 0.7717 - lr: 0.0010\nEpoch 11/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.7065 - accuracy: 0.7571 - val_loss: 0.7382 - val_accuracy: 0.7647 - lr: 0.0010\nEpoch 12/50\n500/500 [==============================] - 31s 61ms/step - loss: 0.6833 - accuracy: 0.7659 - val_loss: 0.6221 - val_accuracy: 0.7938 - lr: 0.0010\nEpoch 13/50\n500/500 [==============================] - 33s 66ms/step - loss: 0.6632 - accuracy: 0.7723 - val_loss: 0.7186 - val_accuracy: 0.7691 - lr: 0.0010\nEpoch 14/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.6458 - accuracy: 0.7793 - val_loss: 0.5874 - val_accuracy: 0.7984 - lr: 0.0010\nEpoch 15/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.6347 - accuracy: 0.7836 - val_loss: 0.6187 - val_accuracy: 0.7966 - lr: 0.0010\nEpoch 16/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5771 - accuracy: 0.8034 - val_loss: 0.5213 - val_accuracy: 0.8274 - lr: 1.0000e-04\nEpoch 17/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5551 - accuracy: 0.8097 - val_loss: 0.5043 - val_accuracy: 0.8327 - lr: 1.0000e-04\nEpoch 18/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5567 - accuracy: 0.8103 - val_loss: 0.5121 - val_accuracy: 0.8302 - lr: 1.0000e-04\nEpoch 19/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5409 - accuracy: 0.8161 - val_loss: 0.5079 - val_accuracy: 0.8333 - lr: 1.0000e-04\nEpoch 20/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5393 - accuracy: 0.8150 - val_loss: 0.5073 - val_accuracy: 0.8349 - lr: 1.0000e-04\nEpoch 21/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5351 - accuracy: 0.8187 - val_loss: 0.4800 - val_accuracy: 0.8434 - lr: 1.0000e-04\nEpoch 22/50\n500/500 [==============================] - 29s 57ms/step - loss: 0.5268 - accuracy: 0.8208 - val_loss: 0.4912 - val_accuracy: 0.8393 - lr: 1.0000e-04\nEpoch 23/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5257 - accuracy: 0.8188 - val_loss: 0.4936 - val_accuracy: 0.8380 - lr: 1.0000e-04\nEpoch 24/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5201 - accuracy: 0.8220 - val_loss: 0.5069 - val_accuracy: 0.8364 - lr: 1.0000e-04\nEpoch 25/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5154 - accuracy: 0.8242 - val_loss: 0.5041 - val_accuracy: 0.8384 - lr: 1.0000e-04\nEpoch 26/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5146 - accuracy: 0.8247 - val_loss: 0.4955 - val_accuracy: 0.8408 - lr: 1.0000e-04\nEpoch 27/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.5100 - accuracy: 0.8256 - val_loss: 0.4945 - val_accuracy: 0.8408 - lr: 1.0000e-04\nEpoch 28/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.5099 - accuracy: 0.8247 - val_loss: 0.4945 - val_accuracy: 0.8391 - lr: 1.0000e-04\nEpoch 29/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.5064 - accuracy: 0.8269 - val_loss: 0.4861 - val_accuracy: 0.8440 - lr: 1.0000e-04\nEpoch 30/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.4995 - accuracy: 0.8285 - val_loss: 0.5292 - val_accuracy: 0.8281 - lr: 1.0000e-04\nEpoch 31/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.4967 - accuracy: 0.8284 - val_loss: 0.4858 - val_accuracy: 0.8421 - lr: 1.0000e-05\nEpoch 32/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.4985 - accuracy: 0.8304 - val_loss: 0.4827 - val_accuracy: 0.8439 - lr: 1.0000e-05\nEpoch 33/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.4904 - accuracy: 0.8317 - val_loss: 0.4786 - val_accuracy: 0.8449 - lr: 1.0000e-05\nEpoch 34/50\n500/500 [==============================] - 30s 60ms/step - loss: 0.4904 - accuracy: 0.8324 - val_loss: 0.4798 - val_accuracy: 0.8451 - lr: 1.0000e-05\nEpoch 35/50\n500/500 [==============================] - 30s 59ms/step - loss: 0.4947 - accuracy: 0.8304 - val_loss: 0.4775 - val_accuracy: 0.8457 - lr: 1.0000e-05\nEpoch 36/50\n500/500 [==============================] - 30s 60ms/step - loss: 0.4972 - accuracy: 0.8298 - val_loss: 0.4844 - val_accuracy: 0.8437 - lr: 1.0000e-05\nEpoch 37/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.4925 - accuracy: 0.8309 - val_loss: 0.4774 - val_accuracy: 0.8460 - lr: 1.0000e-05\nEpoch 38/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.4910 - accuracy: 0.8329 - val_loss: 0.4781 - val_accuracy: 0.8465 - lr: 1.0000e-05\nEpoch 39/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4931 - accuracy: 0.8314 - val_loss: 0.4781 - val_accuracy: 0.8442 - lr: 1.0000e-05\nEpoch 40/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4857 - accuracy: 0.8335 - val_loss: 0.4750 - val_accuracy: 0.8469 - lr: 1.0000e-05\nEpoch 41/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4955 - accuracy: 0.8310 - val_loss: 0.4712 - val_accuracy: 0.8482 - lr: 1.0000e-05\nEpoch 42/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4883 - accuracy: 0.8334 - val_loss: 0.4764 - val_accuracy: 0.8473 - lr: 1.0000e-05\nEpoch 43/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4928 - accuracy: 0.8307 - val_loss: 0.4746 - val_accuracy: 0.8459 - lr: 1.0000e-05\nEpoch 44/50\n500/500 [==============================] - 29s 59ms/step - loss: 0.4854 - accuracy: 0.8334 - val_loss: 0.4784 - val_accuracy: 0.8454 - lr: 1.0000e-05\nEpoch 45/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4851 - accuracy: 0.8350 - val_loss: 0.4804 - val_accuracy: 0.8444 - lr: 1.0000e-05\nEpoch 46/50\n500/500 [==============================] - 29s 57ms/step - loss: 0.4914 - accuracy: 0.8317 - val_loss: 0.4757 - val_accuracy: 0.8470 - lr: 1.0000e-05\nEpoch 47/50\n500/500 [==============================] - 29s 57ms/step - loss: 0.4879 - accuracy: 0.8322 - val_loss: 0.4743 - val_accuracy: 0.8466 - lr: 1.0000e-05\nEpoch 48/50\n500/500 [==============================] - 29s 57ms/step - loss: 0.4902 - accuracy: 0.8333 - val_loss: 0.4730 - val_accuracy: 0.8481 - lr: 1.0000e-05\nEpoch 49/50\n500/500 [==============================] - 29s 58ms/step - loss: 0.4871 - accuracy: 0.8331 - val_loss: 0.4744 - val_accuracy: 0.8477 - lr: 1.0000e-05\nEpoch 50/50\n500/500 [==============================] - 29s 57ms/step - loss: 0.4867 - accuracy: 0.8332 - val_loss: 0.4742 - val_accuracy: 0.8478 - lr: 1.0000e-05\n","output_type":"stream"}]}]}